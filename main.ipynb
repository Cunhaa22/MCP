{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17a491be",
   "metadata": {},
   "source": [
    "Importar bibliotecas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27b7b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pedro\\Desktop\\TESE\\Python\\1\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cst_python_api as cpa\n",
    "from openai import OpenAI\n",
    "from agents.mcp import MCPServerStdio\n",
    "import os\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8eeec2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b40fc4a7",
   "metadata": {},
   "source": [
    "Importar modelo Ollama para processamento local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "102ddffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 6a0746a1ec1a: 100% ▕██████████████████▏ 4.7 GB                         \u001b[K\n",
      "pulling 4fa551d4f938: 100% ▕██████████████████▏  12 KB                         \u001b[K\n",
      "pulling 8ab4849b038c: 100% ▕██████████████████▏  254 B                         \u001b[K\n",
      "pulling 577073ffcc6c: 100% ▕██████████████████▏  110 B                         \u001b[K\n",
      "pulling 3f8eb4da87fa: 100% ▕██████████████████▏  485 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3:8b\n",
    "Ollama=OpenAI(base_url=\"http://localhost:11434/v1\",api_key=\"ollama\")\n",
    "Ollama_Model_name=\"llama3:8b\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4933abd",
   "metadata": {},
   "source": [
    "Criar a interface do chat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c212ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt =\"Você é um especialista em otimizar e desenhar antenas.\"\n",
    "\n",
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = Ollama.chat.completions.create(model=Ollama_Model_name, messages=messages)\n",
    "    answer = response.choices[0].message.content\n",
    "    return answer\n",
    "\n",
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19aff2a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'MCPServerStdio' from 'mcp.client.stdio' (c:\\Users\\pedro\\Desktop\\TESE\\Python\\1\\.venv\\Lib\\site-packages\\mcp\\client\\stdio\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmcp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclient\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstdio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MCPServerStdio\n\u001b[32m      3\u001b[39m params = {\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcommand\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muv\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33margs\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33mrun\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcst_python_api/CST_API_SERVER.py\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      6\u001b[39m }\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m MCPServerStdio(params=params, client_session_timeout_seconds=\u001b[32m30\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m server:\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'MCPServerStdio' from 'mcp.client.stdio' (c:\\Users\\pedro\\Desktop\\TESE\\Python\\1\\.venv\\Lib\\site-packages\\mcp\\client\\stdio\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from mcp.client.stdio import MCPServerStdio\n",
    "\n",
    "params = {\n",
    "    \"command\": \"uv\", \n",
    "    \"args\": [\"run\", \"cst_python_api/CST_API_SERVER.py\"]\n",
    "}\n",
    "\n",
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=30) as server:\n",
    "    mcp_tools = await server.list_tools()\n",
    "    print(mcp_tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40630cc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
